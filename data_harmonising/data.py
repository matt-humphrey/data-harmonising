# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_data.ipynb.

# %% auto 0
__all__ = ['reformat_metadata', 'format_metadata_pyspssio', 'read_sav', 'output_metadata', 'write_sav', 'reorder_columns',
           'Dataset', 'string_to_dict']

# %% ../nbs/01_data.ipynb 3
from fastcore.utils import *
import pandas as pd
from pandas import DataFrame
import numpy as np
import pyreadstat
import pyspssio
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union
import regex as re

# %% ../nbs/01_data.ipynb 5
def reformat_metadata(m1: pyreadstat.metadata_container, # metadata from pyreadstat
                      m2: Dict[str, Dict], # metadata from pyspssio
                      ) -> DataFrame:
      "Combine metadata from pyreadstat and pyspssio and convert into a pandas DataFrame."
      meta={"Label": m1.column_names_to_labels,
            "Field Type": m1.original_variable_types, # Pyreadstat version
            "Field Width": m1.variable_display_width,
            "Decimals": {k: v[2] for k, v in m2['var_formats_tuple'].items()},
            "Variable Type": m1.variable_measure,
            "Field Values": m1.variable_value_labels}
      return DataFrame(data={k: meta[k] for k in meta.keys()}).T

# %% ../nbs/01_data.ipynb 8
#TODO: add testing, include 'var_types' to explicitly set string length
def format_metadata_pyspssio(df: DataFrame,
                            ) -> DataFrame:
    """Take the metadata and convert to appropriate SPSS format."""
    df["Field Width"] = df["Field Width"].astype(int)
    df["Decimals"] = df["Decimals"].astype(int)
    df["Field Values"] = df["Field Values"].map(string_to_dict)

    var_format = {
        "Numeric": "F",
        "String": "A",
        "Date": "DATE"
    }

    df["T"] = df["Field Type"].map(var_format.get)
    df["W"] = df["Field Width"].astype(str)
    df["D"] = df["Decimals"].apply(lambda n: "" if n == 0 else f".{n}")
    df["Field Type"] = df.apply(lambda row: row['T'] + row['W'] + row["D"], axis=1)

    return df.set_index("Variable").T.loc[['Label', 'Field Type', 'Field Width', 'Decimals', 'Variable Type', 'Field Values']]

# %% ../nbs/01_data.ipynb 10
# TODO: write functions to compare df and meta between the packages
def read_sav(file: str, # Path to SPSS file
             index: Optional[str] = None, # column to set as index
            ) -> Tuple[DataFrame, DataFrame]: # Output df and meta as dataframes
      "Wrapper around `pyreadstat.read_sav()` with nicer metadata output."
      _, meta = pyreadstat.read_sav(file)
      df, meta2 = pyspssio.read_sav(file)
      if index: df = df.set_index(index).sort_index()
      meta = reformat_metadata(meta, meta2)
      return df, meta

# %% ../nbs/01_data.ipynb 20
def output_metadata(metadata: pd.DataFrame):
    "Convert metadata from a DataFrame to a nested dictionary to be compatible with pyspssio"
    RENAME_COLUMNS = {
        "Label": "var_labels",
        "Field Type": "var_formats",
        "Field Width": "var_column_widths",
        # "Decimals": , # could write a fn with regex to determine based on var format / field type
        "Variable Type": "var_measure_levels",
        "Field Values": "var_value_labels"
    }
    metadata = (metadata
                .rename(index=RENAME_COLUMNS)
                .T
                .to_dict())
    # Remove instances where values are NaN for compatibility when saving with pyspssio
    metadata = {key: {k: v for k, v in value.items() if not pd.isnull(v)} for key, value in metadata.items()}
    
    return metadata

# %% ../nbs/01_data.ipynb 21
def write_sav(output: str, # path to save file
         df: DataFrame, # raw data (reset index if it's set to "ID")
         meta: DataFrame = None # metadata in DataFrame format
         ) -> None:
    "Wrapper around pyspssio write_sav to handle metadata conversion."
    if df.index.name == "ID": df.reset_index(inplace=True)
    if meta is not None: meta = output_metadata(meta)
    pyspssio.write_sav(output, df, meta)

# %% ../nbs/01_data.ipynb 30
def reorder_columns(
    df: pd.DataFrame, 
    columns_to_move: Union[str, List[str]], 
    position: int = 0, 
    after_column: Optional[str] = None
) -> pd.DataFrame:
    """
    Reorder DataFrame columns, moving specified column(s) to a desired position.

    Args:
    df (pd.DataFrame): Input DataFrame.
    columns_to_move (str or List[str]): Column(s) to move.
    position (int, optional): Position to move the column(s) to. Defaults to 0 (front).
    after_column (str, optional): Column to insert the moved column(s) after. If specified, overrides 'position'.

    Returns:
    pd.DataFrame: DataFrame with reordered columns.

    Raises:
    ValueError: If specified column(s) are not in the DataFrame or if position is invalid.
    """
    if isinstance(columns_to_move, str):
        columns_to_move = [columns_to_move]

    # Check if all specified columns exist in the DataFrame
    missing_columns = set(columns_to_move) - set(df.columns)
    if missing_columns:
        raise ValueError(f"Columns not found in DataFrame: {missing_columns}")

    # Remove columns_to_move from the list of all columns
    remaining_columns = [col for col in df.columns if col not in columns_to_move]

    if after_column:
        if after_column not in df.columns:
            raise ValueError(f"Column '{after_column}' not found in DataFrame")
        position = remaining_columns.index(after_column) + 1
    elif position < 0 or position > len(remaining_columns):
        raise ValueError(f"Invalid position: {position}")

    # Create new column order
    new_order = (
        remaining_columns[:position] + 
        columns_to_move + 
        remaining_columns[position:]
    )

    return df[new_order]

# Usage examples:
# df = reorder_columns(df, 'ID')  # Move 'ID' to the front
# df = reorder_columns(df, ['ID', 'Name'], position=2)  # Move 'ID' and 'Name' to the third position
# df = reorder_columns(df, 'Age', after_column='Name')  # Move 'Age' to after 'Name'

# %% ../nbs/01_data.ipynb 33
class Dataset:
    "A class which contains both the data and metadata for a given data file."
    def __init__(self,
                 df: DataFrame, # the actual raw data
                 meta: DataFrame): # the metadata, including variable labels, value labels, and types for each variable
        self.df, self.meta = df, meta

# %% ../nbs/01_data.ipynb 35
def string_to_dict(input_string: str) -> Dict:
    """Convert metadata from string format to a dictionary."""
    try:
        # Split the string into individual key-value pairs
        pairs = input_string.split(';')
        
        # Construct the dictionary using dictionary comprehension
        result_dict = {
            int(key): value.strip('"')
            for pair in pairs
            for key, value in [re.split(r"(?<![<>])=(?![<>])", pair)]
        }
        
        return result_dict
    except:
        return input_string
