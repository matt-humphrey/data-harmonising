{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "description: class and functions to assist in the task or harmonising variables across\n",
    "  datasets\n",
    "output-file: data.html\n",
    "title: Data Harmonising\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pyreadstat\n",
    "import pyspssio\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for reading an SPSS file, converting the metadata into a dataframe, and then saving the data and metadata to parquet files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def reformat_metadata(m1: pyreadstat.metadata_container, # metadata from pyreadstat\n",
    "                      m2: Dict[str, Dict], # metadata from pyspssio\n",
    "                      ) -> DataFrame:\n",
    "      \"Combine metadata from pyreadstat and pyspssio and convert into a pandas DataFrame.\"\n",
    "      meta={\"Label\": m1.column_names_to_labels,\n",
    "            \"Field Type\": m1.original_variable_types, # Pyreadstat version\n",
    "            \"Field Width\": m1.variable_display_width,\n",
    "            \"Decimals\": {k: v[2] for k, v in m2['var_formats_tuple'].items()},\n",
    "            \"Variable Type\": m1.variable_measure,\n",
    "            \"Field Values\": m1.variable_value_labels}\n",
    "      return DataFrame(data={k: meta[k] for k in meta.keys()}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "file = \"../data/G227_Q.sav\"\n",
    "_, meta = pyreadstat.read_sav(file)\n",
    "_, meta2 = pyspssio.read_sav(file)\n",
    "meta = reformat_metadata(meta, meta2)\n",
    "\n",
    "test_eq(type(meta), DataFrame)\n",
    "test_eq(meta.index, ['Label', 'Field Type', 'Field Width', 'Decimals', 'Variable Type', 'Field Values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to read an SPSS file.\n",
    "Read with two different packages, and compare results; raise warning where differences occur.\n",
    "Combine and filter the metadata from the packages and output it as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# TODO: write functions to compare df and meta between the packages\n",
    "def read_sav(file: str, # Path to SPSS file\n",
    "             index: Optional[str] = None, # column to set as index\n",
    "            ) -> Tuple[DataFrame, DataFrame]: # Output df and meta as dataframes\n",
    "      \"Wrapper around `pyreadstat.read_sav()` with nicer metadata output.\"\n",
    "      _, meta = pyreadstat.read_sav(file)\n",
    "      df, meta2 = pyspssio.read_sav(file)\n",
    "      if index: df = df.set_index(index).sort_index()\n",
    "      meta = reformat_metadata(meta, meta2)\n",
    "      return df, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any differences in how metadata is read between `pyreadstat` and `pyspssio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, meta = pyreadstat.read_sav(file)\n",
    "df2, meta2 = pyspssio.read_sav(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names\n",
    "test_eq(meta.column_names, meta2['var_names'])\n",
    "\n",
    "# Variable labels\n",
    "test_eq(meta.column_names_to_labels, meta2['var_labels'])\n",
    "\n",
    "# Field type\n",
    "# test_eq(meta.original_variable_types, meta2[\"var_formats\"]) # TODO: resolve differences\n",
    "\n",
    "# Field width\n",
    "test_eq(meta.variable_display_width, meta2['var_column_widths'])\n",
    "\n",
    "# Decimals\n",
    "\n",
    "\n",
    "# Variable type\n",
    "test_eq(meta.variable_measure, meta2['var_measure_levels'])\n",
    "\n",
    "# Field values\n",
    "# test_eq(meta.variable_value_labels, meta2['var_value_labels']) # TODO: how to determine which variables have been dropped?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are difference in types, which appears to simply be because the packages handle integers differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G227_PCBY1</th>\n",
       "      <td>F4.0</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_PCBY2</th>\n",
       "      <td>F4.0</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_PCBY3</th>\n",
       "      <td>F4.0</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_PCBY4</th>\n",
       "      <td>F4.0</td>\n",
       "      <td>F4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_BU1A</th>\n",
       "      <td>F3.0</td>\n",
       "      <td>F3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_DQ_CHOC_PD</th>\n",
       "      <td>F8.0</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_DQ_ICECHOC</th>\n",
       "      <td>F8.0</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_DQ_ICECHOC_PD</th>\n",
       "      <td>F8.0</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_DQ_EATCHOC</th>\n",
       "      <td>F8.0</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_DQ_CAFFTAB</th>\n",
       "      <td>F8.0</td>\n",
       "      <td>F8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0      \n",
       "                    self other\n",
       "G227_PCBY1          F4.0    F4\n",
       "G227_PCBY2          F4.0    F4\n",
       "G227_PCBY3          F4.0    F4\n",
       "G227_PCBY4          F4.0    F4\n",
       "G227_BU1A           F3.0    F3\n",
       "...                  ...   ...\n",
       "G227_DQ_CHOC_PD     F8.0    F8\n",
       "G227_DQ_ICECHOC     F8.0    F8\n",
       "G227_DQ_ICECHOC_PD  F8.0    F8\n",
       "G227_DQ_EATCHOC     F8.0    F8\n",
       "G227_DQ_CAFFTAB     F8.0    F8\n",
       "\n",
       "[154 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataFrame(meta.original_variable_types, index=[0]).T.compare(DataFrame(meta2[\"var_formats\"], index=[0]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DataFrame(meta.original_variable_types, index=['Field Type']).T\n",
    "m['Type'] = m['Field Type'].map(lambda s: s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'D', 'A', 'T'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field Type</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G227_DWEL_OTH</th>\n",
       "      <td>A73</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_LIV8_OTH</th>\n",
       "      <td>A14</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_BNF9_OTH</th>\n",
       "      <td>A140</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_HINS4_OTH</th>\n",
       "      <td>A67</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_ED34_OTH</th>\n",
       "      <td>A66</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_HEAR_DIZ_T4A</th>\n",
       "      <td>A31</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_HEAR_SYM7A</th>\n",
       "      <td>A39</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_HEAR_DIZ11A</th>\n",
       "      <td>A35</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_TATT_ADV_DES</th>\n",
       "      <td>A192</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G227_TATT_ADV_CO</th>\n",
       "      <td>A14</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Field Type Type\n",
       "G227_DWEL_OTH            A73    A\n",
       "G227_LIV8_OTH            A14    A\n",
       "G227_BNF9_OTH           A140    A\n",
       "G227_HINS4_OTH           A67    A\n",
       "G227_ED34_OTH            A66    A\n",
       "...                      ...  ...\n",
       "G227_HEAR_DIZ_T4A        A31    A\n",
       "G227_HEAR_SYM7A          A39    A\n",
       "G227_HEAR_DIZ11A         A35    A\n",
       "G227_TATT_ADV_DES       A192    A\n",
       "G227_TATT_ADV_CO         A14    A\n",
       "\n",
       "[229 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.loc[m['Type'] == 'A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define a function for saving SPSS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def output_metadata(metadata: pd.DataFrame):\n",
    "    \"Convert metadata from a DataFrame to a nested dictionary to be compatible with pyspssio\"\n",
    "    RENAME_COLUMNS = {\n",
    "        \"Label\": \"var_labels\",\n",
    "        \"Field Type\": \"var_formats\",\n",
    "        \"Field Width\": \"var_column_widths\",\n",
    "        # \"Decimals\": , # could write a fn with regex to determine based on var format / field type\n",
    "        \"Variable Type\": \"var_measure_levels\",\n",
    "        \"Field Values\": \"var_value_labels\"\n",
    "    }\n",
    "    metadata = (metadata\n",
    "                .rename(index=RENAME_COLUMNS)\n",
    "                .T\n",
    "                .to_dict())\n",
    "    # Remove instances where values are NaN for compatibility when saving with pyspssio\n",
    "    metadata = {key: {k: v for k, v in value.items() if not pd.isnull(v)} for key, value in metadata.items()}\n",
    "    \n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def write_sav(output: str, # path to save file\n",
    "         df: DataFrame, # raw data (reset index if it's set to \"ID\")\n",
    "         meta: DataFrame = None # metadata in DataFrame format\n",
    "         ) -> None:\n",
    "    \"Wrapper around pyspssio write_sav to handle metadata conversion.\"\n",
    "    if df.index.name == \"ID\": df.reset_index(inplace=True)\n",
    "    if meta is not None: meta = output_metadata(meta)\n",
    "    pyspssio.write_sav(output, df, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function to save data as a parquet file for a more efficient storage format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def sav_to_parquet(df: DataFrame, #\n",
    "                   meta: DataFrame, # \n",
    "                   filename: str, # Basename for saving files (ie. for G208_Q.sav, filename=\"G208_Q\")\n",
    "                   dir: str # Directory to save output\n",
    "                   ) -> None:\n",
    "      \"Save data and metadata as parquet files.\"\n",
    "      # Convert metadata to all string types so it behaves nicely when saving as a parquet file\n",
    "      meta = meta.astype(str)\n",
    "      df.to_parquet(Path(dir) / f\"{filename}_df.parquet\")\n",
    "      meta.to_parquet(Path(dir) / f\"{filename}_meta.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, meta = read_sav(file)\n",
    "sav_to_parquet(df, meta, 'G227_Q', '../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that there is no loss or corruption of data in the conversion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pq = pd.read_parquet(\"../data/G227_Q_df.parquet\")\n",
    "test_eq(df, df_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pq = pd.read_parquet(\"../data/G227_Q_meta.parquet\")\n",
    "test_eq(meta.astype(str), meta_pq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset class that holds the raw data and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "    \"A class which contains both the data and metadata for a given data file.\"\n",
    "    def __init__(self,\n",
    "                 df: DataFrame, # the actual raw data\n",
    "                 meta: DataFrame): # the metadata, including variable labels, value labels, and types for each variable\n",
    "        self.df, self.meta = df, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
